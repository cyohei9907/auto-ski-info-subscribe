# Cookie ä¸Šä¼ åŠŸèƒ½å®Œæ•´ä¿®å¤æ–¹æ¡ˆ

## é—®é¢˜æ€»ç»“

ç”¨æˆ·ä¸Šä¼  X.com cookies åï¼Œç‚¹å‡»"å–å¾—æœ€æ–° 10 æ¡"ä»è¿”å› 0 æ¡æ¨æ–‡ï¼Œé‡åˆ°ä»¥ä¸‹é”™è¯¯ï¼š

### é”™è¯¯ 1: sameSite å­—æ®µæ ¼å¼ä¸å…¼å®¹

```
ERROR: BrowserContext.add_cookies: cookies[0].sameSite: expected one of (Strict|Lax|None)
```

**åŸå› **ï¼šCookie-Editor å¯¼å‡ºçš„ cookies åŒ…å« `"sameSite": "no_restriction"` å€¼ï¼Œä½† Playwright åªæ¥å— `Strict`ã€`Lax` æˆ– `None`ã€‚

### é”™è¯¯ 2: Playwright è¶…æ—¶

```
ERROR: Page.goto: Timeout 60000ms exceeded
```

**åŸå› **ï¼šä½¿ç”¨`wait_until='networkidle'`ç­–ç•¥åœ¨ Docker ç¯å¢ƒä¸­ä¸ç¨³å®šï¼Œ60 ç§’è¶…æ—¶ä¸å¤Ÿã€‚

### é”™è¯¯ 3: ç¯å¢ƒå˜é‡æœªè®¾ç½®

ç³»ç»Ÿä»åœ¨ä½¿ç”¨ guest æ¨¡å¼ scraperï¼Œæœªå¯ç”¨ authenticated scraperã€‚

## å®Œæ•´è§£å†³æ–¹æ¡ˆ

### 1. ä¿®å¤ views.py - è½¬æ¢ cookies æ ¼å¼

**æ–‡ä»¶**ï¼š`backend/x_monitor/views.py`

åœ¨ä¿å­˜ cookies å‰ï¼Œå°† Cookie-Editor æ ¼å¼è½¬æ¢ä¸º Playwright å…¼å®¹æ ¼å¼ï¼š

```python
# è½¬æ¢cookiesæ ¼å¼ä»¥å…¼å®¹Playwright
playwright_cookies = []
for cookie in cookies:
    new_cookie = cookie.copy()

    # è½¬æ¢sameSiteå­—æ®µ
    if 'sameSite' in new_cookie:
        same_site = new_cookie['sameSite']
        if same_site in ['no_restriction', 'unspecified']:
            new_cookie['sameSite'] = 'None'
        elif same_site not in ['Strict', 'Lax', 'None']:
            new_cookie['sameSite'] = 'None'
    else:
        new_cookie['sameSite'] = 'Lax'

    # ç¡®ä¿secureå­—æ®µå­˜åœ¨ï¼ˆsameSite=Noneæ—¶å¿…é¡»ä¸ºTrueï¼‰
    if new_cookie.get('sameSite') == 'None' and not new_cookie.get('secure'):
        new_cookie['secure'] = True

    playwright_cookies.append(new_cookie)

# ä¿å­˜è½¬æ¢åçš„cookies
with open(cookies_file, 'w') as f:
    json.dump(playwright_cookies, f, indent=2)
```

### 2. ä¿®å¤ existing cookies æ–‡ä»¶

**ä¸€æ¬¡æ€§ä¿®å¤è„šæœ¬**ï¼ˆåœ¨å®¹å™¨å†…æ‰§è¡Œï¼‰ï¼š

```python
import json
from pathlib import Path

cookies_file = Path('/app/data/x_cookies.json')
with open(cookies_file, 'r') as f:
    cookies = json.load(f)

# ä¿®å¤sameSiteå­—æ®µ
for cookie in cookies:
    if 'sameSite' in cookie:
        same_site = cookie['sameSite']
        if same_site == 'no_restriction':
            cookie['sameSite'] = 'None'
        elif same_site is None or same_site == 'null':
            cookie['sameSite'] = 'Lax'
        elif same_site == 'lax':
            cookie['sameSite'] = 'Lax'
    else:
        cookie['sameSite'] = 'Lax'

    if cookie.get('sameSite') == 'None' and not cookie.get('secure'):
        cookie['secure'] = True

with open(cookies_file, 'w') as f:
    json.dump(cookies, f, indent=2)

print(f'Fixed {len(cookies)} cookies')
```

**æ‰§è¡Œæ–¹å¼**ï¼š

```powershell
@"
[ä¸Šé¢çš„Pythonä»£ç ]
"@ | docker-compose exec -T backend python
```

### 3. ä¿®å¤ authenticated_scraper.py - æé«˜å¯é æ€§

**æ–‡ä»¶**ï¼š`backend/x_monitor/authenticated_scraper.py`

```python
# ä¿®æ”¹å‰ï¼ˆä¸ç¨³å®šï¼‰
page.goto(url, wait_until='networkidle', timeout=60000)

# ä¿®æ”¹åï¼ˆæ›´å¯é ï¼‰
page.goto(url, wait_until='domcontentloaded', timeout=90000)
logger.info("Page loaded, waiting for tweets...")

page.wait_for_selector('article[data-testid="tweet"]', timeout=45000)
logger.info("Tweets detected, waiting for dynamic content...")
page.wait_for_timeout(3000)

# æ·»åŠ è¶…æ—¶å®¹é”™
except PlaywrightTimeoutError as e:
    logger.error(f"Timeout waiting for page: {e}")
    logger.info("Trying to continue with current page state...")
    page.wait_for_timeout(2000)
    # ä¸ç«‹å³è¿”å›ï¼Œå°è¯•ç»§ç»­å¤„ç†
```

**æ”¹è¿›ç‚¹**ï¼š

- âœ… `networkidle` â†’ `domcontentloaded`ï¼ˆæ›´å¿«ï¼Œæ›´å¯é ï¼‰
- âœ… è¶…æ—¶æ—¶é—´ï¼š60 ç§’ â†’ 90 ç§’
- âœ… æ·»åŠ  tweet selector ç­‰å¾…ï¼ˆ45 ç§’ï¼‰
- âœ… è¶…æ—¶åä¸ç«‹å³å¤±è´¥ï¼Œå°è¯•ç»§ç»­

### 4. docker-compose.yml - å¯ç”¨ authenticated scraper

**æ–‡ä»¶**ï¼š`docker-compose.yml`

```yaml
backend:
  environment:
    USE_AUTHENTICATED_SCRAPER: "True" # âœ… æ–°å¢
  command: >
    gunicorn --bind 0.0.0.0:8000 --workers 3 --timeout 600 auto_ski_info.wsgi:application
    # timeout ä» 300 â†’ 600ç§’

celery:
  environment:
    USE_AUTHENTICATED_SCRAPER: "True" # âœ… æ–°å¢

celery-beat:
  environment:
    USE_AUTHENTICATED_SCRAPER: "True" # âœ… æ–°å¢
```

## åº”ç”¨æ‰€æœ‰ä¿®å¤

### æ­¥éª¤ 1: åœæ­¢æ‰€æœ‰æœåŠ¡

```bash
docker-compose down
```

### æ­¥éª¤ 2: å¯åŠ¨æ‰€æœ‰æœåŠ¡

```bash
docker-compose up -d
```

### æ­¥éª¤ 3: ä¿®å¤ç°æœ‰ cookies æ–‡ä»¶

```powershell
# æ‰§è¡Œä¸Šé¢çš„Pythonä¿®å¤è„šæœ¬
@"
import json
from pathlib import Path
# [å®Œæ•´ä»£ç è§ä¸Š]
"@ | docker-compose exec -T backend python
```

### æ­¥éª¤ 4: éªŒè¯é…ç½®

```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
docker-compose exec backend env | grep USE_AUTHENTICATED_SCRAPER
# åº”è¾“å‡º: USE_AUTHENTICATED_SCRAPER=True

# æ£€æŸ¥æ—¥å¿—
docker-compose logs backend | grep "authenticated scraper"
# åº”åŒ…å«: "Using authenticated X.com scraper (requires cookies, can access full timeline)"

# æ£€æŸ¥cookiesæ–‡ä»¶
docker-compose exec backend cat /app/data/x_cookies.json | grep sameSite
# æ‰€æœ‰å€¼åº”ä¸º "Lax" æˆ– "None"ï¼Œä¸åº”æœ‰ "no_restriction"
```

## æµ‹è¯•æµç¨‹

### æ–¹å¼ 1: ä½¿ç”¨ç°æœ‰ cookiesï¼ˆå·²ä¿®å¤ï¼‰

1. è®¿é—® http://localhost:3000/accounts
2. ç‚¹å‡»ä»»æ„è´¦æˆ·çš„"å–å¾—æœ€æ–° 10 æ¡"æŒ‰é’®
3. ç­‰å¾… 2-3 åˆ†é’Ÿï¼ˆåŒ…æ‹¬ 15-30 ç§’éšæœºå»¶è¿Ÿ + é¡µé¢åŠ è½½ï¼‰
4. **é¢„æœŸ**ï¼šæˆåŠŸè·å– 10 æ¡æ¨æ–‡

### æ–¹å¼ 2: é‡æ–°ä¸Šä¼  cookies

1. åœ¨æµè§ˆå™¨ç™»å½• X.comï¼ˆGoogle è´¦å·ï¼‰
2. ä½¿ç”¨ Cookie-Editor å¯¼å‡º cookies
3. è®¿é—® http://localhost:3000/settings
4. åˆ‡æ¢åˆ°"ä¸Šä¼  Cookies"æ ‡ç­¾é¡µ
5. ç²˜è´´ JSON å¹¶ä¸Šä¼ 
6. **ç°åœ¨ä¼šè‡ªåŠ¨è½¬æ¢æ ¼å¼**
7. è¿”å›è´¦æˆ·é¡µé¢æµ‹è¯•

## æ³¨æ„äº‹é¡¹

### Playwright åœ¨ Docker ä¸­çš„è¶…æ—¶é—®é¢˜

Docker ç¯å¢ƒç½‘ç»œå»¶è¿Ÿè¾ƒé«˜ï¼Œå»ºè®®ï¼š

- âœ… ä½¿ç”¨ `domcontentloaded` è€Œé `networkidle`
- âœ… è¶…æ—¶è®¾ç½® 90 ç§’+
- âœ… åœ¨ selector ç­‰å¾…å¤±è´¥æ—¶æœ‰é™çº§ç­–ç•¥

### Cookies æœ‰æ•ˆæœŸ

- X.com cookies é€šå¸¸æœ‰æ•ˆæœŸ **30-90 å¤©**
- å¦‚æœé•¿æ—¶é—´æœªä½¿ç”¨ï¼Œå¯èƒ½éœ€è¦é‡æ–°ç™»å½•
- å®šæœŸæ£€æŸ¥æ˜¯å¦è¿”å› 0 æ¡æ¨æ–‡ï¼ˆå¯èƒ½æ˜¯ cookies è¿‡æœŸï¼‰

### Rate Limiting

- ä»£ç å·²å®ç° **15-30 ç§’éšæœºå»¶è¿Ÿ**
- é¿å…é¢‘ç¹ç‚¹å‡»"å–å¾—æœ€æ–° 10 æ¡"
- å®šæ—¶ä»»åŠ¡å·²è€ƒè™‘å»¶è¿Ÿ

## æ•…éšœæ’æŸ¥

### å¦‚æœä»ç„¶è·å– 0 æ¡æ¨æ–‡

1. **æ£€æŸ¥ cookies æ˜¯å¦æœ‰æ•ˆ**

```bash
docker-compose exec backend cat /app/data/x_cookies.json | grep auth_token
```

åº”è¯¥çœ‹åˆ° `auth_token` cookie å­˜åœ¨ä¸”æœ‰é•¿ valueã€‚

2. **æ£€æŸ¥æ—¥å¿—è¯¦ç»†é”™è¯¯**

```bash
docker-compose logs backend -f
```

æŸ¥çœ‹æ˜¯å¦æœ‰ Playwright é”™è¯¯æˆ–ç½‘ç»œé”™è¯¯ã€‚

3. **æ‰‹åŠ¨æµ‹è¯• cookies**
   åœ¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·ä¸­ï¼Œæ‰‹åŠ¨æ·»åŠ å¯¼å‡ºçš„ cookies å¹¶è®¿é—® https://x.comï¼Œçœ‹æ˜¯å¦èƒ½ä»¥ç™»å½•çŠ¶æ€è®¿é—®ã€‚

4. **æ£€æŸ¥ X.com è´¦æˆ·çŠ¶æ€**
   å¦‚æœ X è´¦æˆ·è¢«é™åˆ¶æˆ–é”å®šï¼Œå³ä½¿ cookies æœ‰æ•ˆä¹Ÿæ— æ³•è·å–æ•°æ®ã€‚

5. **Docker ç½‘ç»œé—®é¢˜**

```bash
# æµ‹è¯•å®¹å™¨èƒ½å¦è®¿é—®x.com
docker-compose exec backend curl -I https://x.com
```

## ç›¸å…³æ–‡ä»¶æ¸…å•

- âœ… `backend/x_monitor/views.py` - Cookie ä¸Šä¼  APIï¼ˆæ ¼å¼è½¬æ¢ï¼‰
- âœ… `backend/x_monitor/authenticated_scraper.py` - è®¤è¯çˆ¬è™«ï¼ˆè¶…æ—¶ä¼˜åŒ–ï¼‰
- âœ… `backend/x_monitor/services.py` - Scraper é€‰æ‹©é€»è¾‘
- âœ… `docker-compose.yml` - ç¯å¢ƒå˜é‡é…ç½®
- âœ… `backend/data/x_cookies.json` - Cookies å­˜å‚¨ï¼ˆå·²ä¿®å¤ï¼‰
- âœ… `frontend/src/pages/SettingsPage.js` - Cookie ä¸Šä¼ ç•Œé¢
- âœ… `frontend/src/services/api.js` - API è°ƒç”¨

## ä¿®å¤å®Œæˆæ—¶é—´

2025-11-07 00:24 JST

## çŠ¶æ€

ğŸŸ¢ **æ‰€æœ‰é—®é¢˜å·²ä¿®å¤ï¼Œå¯ä»¥æµ‹è¯•**

## ä¸‹ä¸€æ­¥

è¯·è®¿é—® http://localhost:3000/accounts æµ‹è¯•"å–å¾—æœ€æ–° 10 æ¡"åŠŸèƒ½ï¼
